{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.2\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "print(cv2.__version__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/gradiente.png\")\n",
    "plt.title(\"Imagem Original\")\n",
    "plt.imshow(image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
    "plt.title(\"Limiarização binária\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY_INV)\n",
    "plt.title(\"Limiarização binária invertida\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, t_image = cv2.threshold(image, 127, 255, cv2.THRESH_TRUNC)\n",
    "plt.title(\"Limiarização por truncagem\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO)\n",
    "plt.title(\"Limiarização para zero\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 127, 255, cv2.THRESH_TOZERO_INV)\n",
    "plt.title(\"Limiarização para zero invertido\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, t_image = cv2.threshold(image, 0, 255, cv2.THRESH_TRUNC)\n",
    "plt.title(\"Limiarização por truncagem\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 0, 255, cv2.THRESH_TOZERO)\n",
    "plt.title(\"Limiarização para zero\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 0, 255, cv2.THRESH_TOZERO_INV)\n",
    "plt.title(\"Limiarização para zero invertido\")\n",
    "plt.imshow(t_image)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/sudoku.jpg\", cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Document Original\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "ret, t_image = cv2.threshold(image, 100, 255, cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Document Binary Threshold\", t_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "ret, t_image = cv2.threshold(image_blur, 90, 255,cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Document Blurred and Threshold\",t_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "t_image = cv2.adaptiveThreshold(image_blur, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "cv2.imshow(\"Document Adaptative Filter\", t_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/lanes.png\",cv2.IMREAD_GRAYSCALE)\n",
    "cv2.imshow(\"Lanes\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "image_blur = cv2.GaussianBlur(image, (5,5), 0)\n",
    "ret, t_image = cv2.threshold(image_blur, 200, 255,\n",
    "cv2.THRESH_BINARY)\n",
    "cv2.imshow(\"Document Blurred and Threshold\", t_image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = np.ones((5,5), np.uint8)\n",
    "image_dilated = cv2.dilate(t_image, kernel,iterations=1)\n",
    "cv2.imshow(\"Lanes Dilated\", image_dilated)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "kernel = np.ones((5,5), np.uint8)\n",
    "image_eroded = cv2.erode(image_dilated, kernel,iterations=1)\n",
    "cv2.imshow(\"Lanes Eroded\", image_eroded)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritimo de Sobel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/thanos2.png\",cv2.IMREAD_GRAYSCALE)\n",
    "ret,binary = cv2.threshold(image, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "sobel_x = cv2.Sobel(binary, cv2.CV_64F, 0, 1, ksize=5)\n",
    "sobel_y = cv2.Sobel(binary, cv2.CV_64F, 1, 0, ksize=5)\n",
    "\n",
    "cv2.imshow(\"Thanos Sobel X\", sobel_x)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.imshow(\"Thanos Sobel Y\", sobel_y)\n",
    "cv2.waitKey()\n",
    "\n",
    "sobel_xy = cv2.bitwise_or(sobel_x, sobel_y)\n",
    "cv2.imshow(\"Thanos Sobel XY\", sobel_y)\n",
    "cv2.waitKey()\n",
    "\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "laplacian = cv2.Laplacian(binary, cv2.CV_64F)\n",
    "cv2.imshow(\"Thanos Laplacian\", laplacian)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canny = cv2.Canny(binary, 30, 190)\n",
    "cv2.imshow(\"Thanos Canny\", canny)\n",
    "cv2.waitKey()\n",
    "\n",
    "canny = cv2.Canny(image, 70, 150)\n",
    "cv2.imshow(\"Thanos Canny Grayscale\", canny)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Desafio 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crie uma função para transformar uma imagem colorida em um desenho\n",
    "(sketch) com fundo branco e traços na cor preta.\n",
    "A imagem abaixo de exemplo se encontra na pasta imagens no\n",
    "repositório do GitHub.\n",
    "Experimente sua webcam par ter o efeito on-line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sketch_transform(image):\n",
    "    image_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    image_grayscale_blurred = cv2.GaussianBlur(image_grayscale, (7,7), 0)\n",
    "    image_canny = cv2.Canny(image_grayscale_blurred, 10, 80)\n",
    "    _, mask = image_canny_inverted = cv2.threshold(image_canny, 30, 255, cv2.THRESH_BINARY_INV)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageDesafio = cv2.imread(\"imagens/robocop.jpg\")\n",
    "cv2.imshow(\"Robocop\", imageDesafio)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageTratada = sketch_transform(imageDesafio)\n",
    "cv2.imshow(\"Robocop Invertido\", imageTratada)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_capture = cv2.VideoCapture(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "while True:\n",
    "    _, image_frame = cam_capture.read()\n",
    "    cv2.imshow(\"Sketcher\", sketch_transform(image_frame))\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cam_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cam_capture.release()\n",
    "cam_capture = cv2.VideoCapture(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "upper_left = (50, 50)\n",
    "bottom_right = (300, 300)\n",
    "\n",
    "while True:\n",
    "    _, image_frame = cam_capture.read()\n",
    "    \n",
    "    #Rectangle marker\n",
    "    r = cv2.rectangle(image_frame, upper_left, bottom_right, (100, 50, 200), 5)\n",
    "    rect_img = image_frame[upper_left[1] : bottom_right[1], upper_left[0] : bottom_right[0]]\n",
    "    \n",
    "    sketcher_rect = rect_img\n",
    "    sketcher_rect = sketch_transform(sketcher_rect)\n",
    "    \n",
    "    #Conversion for 3 channels to put back on original image (streaming)\n",
    "    sketcher_rect_rgb = cv2.cvtColor(sketcher_rect, cv2.COLOR_GRAY2RGB)\n",
    "    \n",
    "    #Replacing the sketched image on Region of Interest\n",
    "    image_frame[upper_left[1] : bottom_right[1], upper_left[0] : bottom_right[0]] = sketcher_rect_rgb\n",
    "\n",
    "    cv2.imshow(\"Sketcher ROI\", image_frame)\n",
    "    if cv2.waitKey(1) == 13:\n",
    "        break\n",
    "        \n",
    "cam_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentação de Imagens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Carregando a Imagem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"imagens/formas_1.png\")\n",
    "cv2.imshow(\"Formas 1\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pegou o contorno da imagem**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_grayscale = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "image_edged = cv2.Canny(image_grayscale, 30, 180)\n",
    "cv2.imshow(\"Formas 1 Edged\", image_edged)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Encontra os contornos e retorna a quantidade**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contornos encontrados 3\n"
     ]
    }
   ],
   "source": [
    "_, contours, hierarchy = cv2.findContours(image_edged,cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contours)))\n",
    "cv2.drawContours(image, contours, -1, (0,0,255), 3)\n",
    "cv2.imshow(\"Formas 1 Contours\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(392, 392, 3)\n"
     ]
    }
   ],
   "source": [
    "image = cv2.imread(\"imagens/shapes.jpg\")\n",
    "print(image.shape)\n",
    "\n",
    "cv2.imshow(\"Formas Diversas\", image)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "blank_canvas = np.zeros((image.shape[0], image.shape[1], 3))\n",
    "image_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_edged = cv2.Canny(image, 40, 180)\n",
    "\n",
    "cv2.imshow(\"Formas Diversas Edged\", image_edged)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contornos encontrados 8\n"
     ]
    }
   ],
   "source": [
    "_, contours, hierarchy = cv2.findContours(image_edged, cv2.RETR_EXTERNAL,\n",
    "cv2.CHAIN_APPROX_SIMPLE)\n",
    "print(\"Contornos encontrados \"+str(len(contours)))\n",
    "cv2.drawContours(blank_canvas, contours, -1, (0,255,0), 2)\n",
    "cv2.imshow(\"Formas Diversas Blank Contours\", blank_canvas)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4680.0, 100.0, 0.0, 5829.5, 4236.5, 0.5, 87.0, 4851.0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def areas_contornos(contornos):\n",
    "    areas = []\n",
    "    for contorno in contornos:\n",
    "        area = cv2.contourArea(contorno)\n",
    "        areas.append(area)\n",
    "    return areas\n",
    "\n",
    "areas_contornos(contours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 6)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contornos_cleaned = []\n",
    "\n",
    "for contorno in contours:\n",
    "    if cv2.contourArea(contorno) > 1:\n",
    "        contornos_cleaned.append(contorno)\n",
    "            \n",
    "len(contours), len(contornos_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_centroide(image, contorno, label):\n",
    "    M = cv2.moments(contorno)\n",
    "    cx = int(M[\"m10\"]/M[\"m00\"])\n",
    "    cy = int(M[\"m01\"]/M[\"m00\"])\n",
    "    cv2.putText(image, str(label), (cx, cy),\n",
    "    cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "contornos_sorted = sorted(contornos_cleaned, key=cv2.contourArea,reverse=True)\n",
    "image_countor = image.copy()\n",
    "for idx, contorno in enumerate(contornos_sorted):\n",
    "    label_centroide(image_countor, contorno, idx+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"Formas Diversas Contours\", image_countor)\n",
    "cv2.waitKey()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
